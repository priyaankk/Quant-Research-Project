{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c956c15-3288-43fa-a01c-9918b2bb5741",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a39b433-7206-4a0b-9ef5-4aa5596ac3be",
   "metadata": {},
   "source": [
    "Given data has a few missing points. It also has IV values for non-market hours and holidays. I have cleaned the data and added approximate values for missing points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac38a1dd-641e-47b1-96e3-c66c40d0e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_parquet('data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7075e509-4ca2-4152-8422-ae023bc27fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "# Removing Weekends and Non-Market Hours\n",
    "filtered_df = df[\n",
    "    (df.index.dayofweek < 5) &  \n",
    "    (df.index.time >= pd.to_datetime(\"09:15\").time()) &  \n",
    "    (df.index.time <= pd.to_datetime(\"15:30\").time())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446597aa-1f7b-4cc7-b1e3-36fd0370e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are missing values in the DataFrame.\n",
      "banknifty    267\n",
      "nifty        350\n",
      "tte            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing data\n",
    "if filtered_df.isnull().any().any():\n",
    "    print(\"There are missing values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"No missing values found in the DataFrame.\")\n",
    "\n",
    "# Calculating number of missing values for all columns\n",
    "missing_data = filtered_df.isnull().sum()\n",
    "\n",
    "# Printing number of missing values for all columns\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8054358-9583-4f81-8090-d0685559e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a function which would fill empty cells with the average value of IV before and after the cell\n",
    "# This assumption came from an observation of the dataset\n",
    "def fill_missing_with_avg(df):\n",
    "    for column in df.columns:\n",
    "        for i, index_value in enumerate(df.index):\n",
    "            if pd.isna(df.loc[index_value, column]):\n",
    "                above = df.loc[df.index[i - 1], column] if i > 0 else None\n",
    "                below = df.loc[df.index[i + 1], column] if i < len(df) - 1 else None\n",
    "                if pd.notna(above) and pd.notna(below):\n",
    "                    df.loc[index_value, column] = (above + below) / 2\n",
    "                elif pd.notna(above):\n",
    "                    df.loc[index_value, column] = above\n",
    "                elif pd.notna(below):\n",
    "                    df.loc[index_value, column] = below\n",
    "                # If both above and below are NaN, the missing value remains NaN\n",
    "    return df\n",
    "\n",
    "filled_df = fill_missing_with_avg(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12bfa710-d6e7-440a-b5a5-b0e28e87a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found in the DataFrame.\n",
      "banknifty    0\n",
      "nifty        0\n",
      "tte          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking if there is missing data now, since there was a case where both values above and below would be NaN, would leave NaN\n",
    "if filled_df.isnull().any().any():\n",
    "    print(\"There are missing values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"No missing values found in the DataFrame.\")\n",
    "\n",
    "missing_data = filled_df.isnull().sum()\n",
    "\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9e6f8c-3758-438c-a3d4-49b1fd17c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filled_df.copy(deep=True)\n",
    "df['Spread'] = df['banknifty'] - df['nifty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e54e7a6d-14ce-42b4-8dca-16b5225060fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(data, period=1875):\n",
    "  rol_mean = data.rolling(period).mean()\n",
    "  rol_std = data.rolling(period).std()\n",
    "  z = (data-rol_mean)/rol_std\n",
    "  return z\n",
    "\n",
    "df['z-score'] = z_score(df['Spread']) # calculating z-score using a rolling window of 5 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51579855-58c5-4678-b284-d728ca686e6a",
   "metadata": {},
   "source": [
    "# Z - Score Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ceb96-2d13-4c9c-bdf4-85e2e19ff126",
   "metadata": {},
   "source": [
    "The P/L formula we were given in assignment was\n",
    "P/L = (Bank Nifty IV - Nifty IV)* (Time to Expiry)**0.7\n",
    "However, at all times in the dataframe, Bank Nifty IV is greater than Nifty IV. P/L was always positive.\n",
    "In such a case, there is no scope for a strategy. I have applied certain assumptions to make this a bit fair trading strategy.\n",
    "\n",
    "We are calculating the z-score of spread and applying mean reversion strategy to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796ff39-8259-4469-b06c-7a9b75b72f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = df['z-score']\n",
    "spreads = df['Spread']\n",
    "ttes = df['tte']\n",
    "times = df.index.values\n",
    "signal_type = []#\n",
    "entry_time_new = []#\n",
    "exit_time_new = []#\n",
    "spread_for_entry_new = []#\n",
    "spread_for_exit_new = []#\n",
    "pnl_new = []\n",
    "\n",
    "number_of_long_trades = 0\n",
    "number_of_short_trades = 0\n",
    "\n",
    "long = False\n",
    "short = False\n",
    "z_threshold = 1\n",
    "for index, z_score in enumerate(z_scores):\n",
    "    if z_score<-1*z_threshold and long is False:\n",
    "        #print(\"entering long\")\n",
    "        number_of_long_trades += 1\n",
    "        long = True\n",
    "        signal_type.append(1)\n",
    "        entry_time_new.append(times[index])\n",
    "        spread_for_entry_new.append(spreads[index])\n",
    "        print(\"entering long at \",spreads[index])\n",
    "\n",
    "    if z_score<-1*z_threshold and long is True:\n",
    "        #print(\"continuing long\")\n",
    "        pass\n",
    "\n",
    "    if z_score>0 and long is True:\n",
    "        #print(\"exiting long\")\n",
    "        long = False\n",
    "        spread_for_exit_new.append(spreads[index])\n",
    "        exit_spread_long = spreads[index]\n",
    "        #print(\"we added \")\n",
    "        #print(\"exiting long at \",spreads[index])\n",
    "        entry_spread_long = spread_for_entry_new[-1]\n",
    "        tte_long = ttes[index]\n",
    "        pnl_long = (exit_spread_long-entry_spread_long)*(ttes[index])**(0.7)\n",
    "        exit_time_new.append(times[index])\n",
    "        pnl_new.append(pnl_long)\n",
    "    \n",
    "    if z_score>z_threshold and short is False:\n",
    "        #print(\"entering short\")\n",
    "        number_of_short_trades += 1\n",
    "        short = True\n",
    "        signal_type.append(-1)\n",
    "        entry_time_new.append(times[index])\n",
    "        spread_for_entry_new.append(spreads[index])\n",
    "\n",
    "    if z_score>z_threshold and short is True:\n",
    "        #print(\"continuing short\")\n",
    "        pass\n",
    "\n",
    "    if z_score<0 and short is True:\n",
    "        #print(\"exiting short\")\n",
    "        short = False\n",
    "        exit_spread_short = spreads[index]\n",
    "        entry_spread_short = spread_for_entry_new[-1]\n",
    "        spread_for_exit_new.append(exit_spread_short)\n",
    "        exit_time_new.append(times[index])\n",
    "        tte_long = ttes[index]\n",
    "        pnl_short = (entry_spread_short-exit_spread_short)*(ttes[index])**(0.7)\n",
    "        pnl_new.append(pnl_short)\n",
    "        \n",
    "losses_in_long_count = sum(1 for return_long in long_returns_list if return_long < 0)\n",
    "losses_in_short_count = sum(1 for return_short in short_returns_list if return_short < 0)\n",
    "\n",
    "\n",
    "signal_type_modified = ['Long' if signal == 1 else 'Short' for signal in signal_type]\n",
    "final_df = pd.DataFrame({\n",
    "    'Time_entry': entry_time_new,\n",
    "    'Time_exit': exit_time_new,\n",
    "    'Entry_spread': spread_for_entry_new,\n",
    "    'Exit_spread': spread_for_exit_new,\n",
    "    'PnL': pnl_new,\n",
    "    'Signal': signal_type_modified\n",
    "})\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
